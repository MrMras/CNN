{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import concurrent.futures\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBordersHorizontal(img, border, side):\n",
    "    if side == \"l2r\":\n",
    "        for i in range(border):\n",
    "            if np.sum(img[:,i]) > 0:\n",
    "                return i\n",
    "    elif side == \"r2l\":\n",
    "        for i in range(img.shape[1] - 1, border, -1):\n",
    "            if np.sum(img[:,i]) > 0:\n",
    "                return i\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return border\n",
    "\n",
    "def findBordersVertical(img, border, side):\n",
    "    if side == \"t2b\":\n",
    "        for i in range(border):\n",
    "            if np.sum(img[i]) > 0:\n",
    "                return i\n",
    "    elif side == \"b2t\":\n",
    "        for i in range(img.shape[0] - 1, border, -1):\n",
    "            if np.sum(img[i]) > 0:\n",
    "                return i\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return border\n",
    "\n",
    "\n",
    "def findBorders(img, bordLeft, bordRight, bordTop, bordBottom):\n",
    "    bordLeft = findBordersHorizontal(img, bordLeft, \"l2r\")\n",
    "    bordRight = findBordersHorizontal(img, bordRight, \"r2l\")\n",
    "    bordTop = findBordersVertical(img, bordTop, \"t2b\")\n",
    "    bordBottom = findBordersVertical(img, bordBottom, \"b2t\")\n",
    "    return bordLeft, bordRight, bordTop, bordBottom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding borders: 1340it [00:30, 44.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 1162 283 1059\n",
      "Initial shape: (776, 1046)\n",
      "Extras : (8, 22)\n",
      "New shape: (768, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to find borders for a single image\n",
    "def find_borders(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return findBorders(img, img.shape[0] - 1, 0, img.shape[1] - 1, 0)\n",
    "\n",
    "# Function to merge borders from multiple images\n",
    "def merge_borders(borders):\n",
    "    bordLeft, bordRight, bordTop, bordBottom = borders[0]\n",
    "    for b in borders[1:]:\n",
    "        bordLeftTmp, bordRightTmp, bordTopTmp, bordBottomTmp = b\n",
    "        bordLeft = min(bordLeft, bordLeftTmp)\n",
    "        bordRight = max(bordRight, bordRightTmp)\n",
    "        bordTop = min(bordTop, bordTopTmp)\n",
    "        bordBottom = max(bordBottom, bordBottomTmp)\n",
    "    return bordLeft, bordRight, bordTop, bordBottom\n",
    "\n",
    "# path to the folder with already segmented data\n",
    "path_folder = \"./preparations/data/outdata/\"\n",
    "\n",
    "# get a list of paths to the files\n",
    "dirs = os.listdir(path_folder)\n",
    "path_files = [os.path.join(path_folder, x) for x in dirs]\n",
    "\n",
    "# Number of threads to use\n",
    "num_threads = min(len(path_files), 4)  # Adjust the number of threads as needed\n",
    "\n",
    "borders = []\n",
    "\n",
    "# Use ThreadPoolExecutor to parallelize the finding of borders\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    # Submit tasks for each image to find borders concurrently\n",
    "    futures = [executor.submit(find_borders, path) for path in path_files]\n",
    "\n",
    "    # Collect results\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures), \"Finding borders\"):\n",
    "        borders.append(future.result())\n",
    "\n",
    "# Merge borders from multiple images\n",
    "bordLeft, bordRight, bordTop, bordBottom = merge_borders(borders)\n",
    "\n",
    "print(bordLeft, bordRight, bordTop, bordBottom)\n",
    "\n",
    "horizontal = bordRight - bordLeft\n",
    "vertical = bordBottom - bordTop\n",
    "\n",
    "print(\"Initial shape: ({0}, {1})\".format(vertical, horizontal))\n",
    "\n",
    "horizontalExtra = horizontal % config.WIDTH\n",
    "verticalExtra = vertical % config.HEIGHT\n",
    "\n",
    "print(\"Extras : ({0}, {1})\".format(verticalExtra, horizontalExtra))\n",
    "\n",
    "bordLeft = int(bordLeft + horizontalExtra / 2)\n",
    "bordRight = int(bordRight - horizontalExtra / 2)\n",
    "\n",
    "bordTop = int(bordTop + verticalExtra / 2)\n",
    "bordBottom = int(bordBottom - verticalExtra / 2)\n",
    "\n",
    "horizontal = bordRight - bordLeft\n",
    "vertical = bordBottom - bordTop\n",
    "\n",
    "print(\"New shape: ({0}, {1})\".format(vertical, horizontal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_data(in_path1, in_path2, out_path1, out_path2, borders):\n",
    "    # Extracting border coordinates\n",
    "    bordTop, bordLeft = borders\n",
    "    # Starting index for saving images\n",
    "    ind = 1000000\n",
    "    # List of files in input paths\n",
    "    files_in1 = os.listdir(in_path1)\n",
    "    files_in2 = os.listdir(in_path2)\n",
    "    # List to store mean intensities of processed images\n",
    "    sizes = np.array([])\n",
    "\n",
    "    # Calculating the number of splits vertically and horizontally\n",
    "    vertical_split = vertical // config.HEIGHT\n",
    "    horizontal_split = horizontal // config.WIDTH\n",
    "         \n",
    "    # Calculating grid size\n",
    "    grid_size = vertical_split * horizontal_split\n",
    "    \n",
    "    for i in tqdm(range(vertical_split * horizontal_split), desc=\"Processing\"):\n",
    "        # Calculate the grid indices\n",
    "        j = i % horizontal_split\n",
    "        k = i // horizontal_split\n",
    "\n",
    "        # Iterate through the image files in batches\n",
    "        for i in range(0, len(files_in2) - len(files_in2) % config.NUM_PICS, config.NUM_PICS):\n",
    "            # Initialize a list to store intensities for each image in the group\n",
    "            group_intensities = np.array([])\n",
    "\n",
    "            # Iterate through the images in the current group\n",
    "            for l, x in enumerate(files_in2[i:i+config.NUM_PICS]):\n",
    "                # Read and extract a region of interest from the image\n",
    "                img_tmp1 = cv2.imread(os.path.join(in_path1, x), cv2.IMREAD_GRAYSCALE)\n",
    "                img_tmp1 = img_tmp1[bordTop + config.HEIGHT * k: bordTop + config.HEIGHT * (k + 1), bordLeft + config.WIDTH * j: bordLeft + config.WIDTH * (j + 1)]\n",
    "                # Calculate and store the mean intensity of the current image\n",
    "                group_intensities = np.append(group_intensities, np.mean(img_tmp1))\n",
    "\n",
    "            # Calculate the average intensity for the current group\n",
    "            average_intensity = np.mean(group_intensities)\n",
    "\n",
    "            # Store the average intensity in the 'sizes' list\n",
    "            sizes = np.append(sizes, average_intensity)\n",
    "\n",
    "    # Calculating the median of the mean intensities\n",
    "    print(sizes.dtype)\n",
    "    non_zero_values = sizes[sizes != 0]\n",
    "    print(\"Uniques:\", np.unique(sizes))\n",
    "    med = np.median(non_zero_values)\n",
    "    print(\"Median\", med)\n",
    "    mean = np.mean(non_zero_values)\n",
    "    print(\"Mean\", mean)\n",
    "    # print(f\"length - {len(files_in1)}\")\n",
    "    # print(f\"length of sizes - {len(sizes)}\")\n",
    "    # print(f\"grid_size - {grid_size}\")\n",
    "    # Iterating through each set of images and writing selected ones\n",
    "    for i in tqdm(range(len(sizes)), \"Writting images\"):\n",
    "        # Checking if the mean intensity of the set is greater than or equal to the median\n",
    "        if sizes[i] >= med:\n",
    "            # Extracting indices for the selected set of images\n",
    "            pic_number = [(i * config.NUM_PICS + j) % (len(files_in1) -  len(files_in1) % config.NUM_PICS) for j in range(config.NUM_PICS)]\n",
    "            horizontal_number = i // ((len(files_in1) -  len(files_in1) % config.NUM_PICS) // config.NUM_PICS) % horizontal_split\n",
    "            vertical_number = i // ((len(files_in1) -  len(files_in1) % config.NUM_PICS) // config.NUM_PICS) // horizontal_split\n",
    "\n",
    "            # Iterating through images in the selected set and writing them\n",
    "            for k in range(config.NUM_PICS):\n",
    "                \n",
    "                # print(f\"i - {i}\\nk - {k}\\npic_number[k] - {pic_number[k]}\")\n",
    "                img_tmp1 = cv2.imread(os.path.join(in_path1, files_in1[pic_number[k]]), cv2.IMREAD_GRAYSCALE)\n",
    "                img_tmp2 = cv2.imread(os.path.join(in_path2, files_in2[pic_number[k]]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                img_tmp1 = img_tmp1[bordTop  + config.HEIGHT * vertical_number: bordTop  + config.HEIGHT * (vertical_number + 1), bordLeft + config.WIDTH * horizontal_number : bordLeft + config.WIDTH * (horizontal_number + 1)]\n",
    "                img_tmp2 = img_tmp2[bordTop  + config.HEIGHT * vertical_number: bordTop  + config.HEIGHT * (vertical_number + 1), bordLeft + config.WIDTH * horizontal_number : bordLeft + config.WIDTH * (horizontal_number + 1)]\n",
    "                cv2.imwrite(os.path.join(out_path1, f\"img_{ind}_{k}.png\"), img_tmp1)\n",
    "                cv2.imwrite(os.path.join(out_path2, f\"img_{ind}_{k}.png\"), img_tmp2)\n",
    "            ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 192/192 [40:00<00:00, 12.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "Uniques: [0.00000000e+00 1.55639648e-02 3.11279297e-02 ... 1.66658936e+02\n",
      " 1.79483643e+02 1.87359009e+02]\n",
      "Median 5.9454345703125\n",
      "Mean 7.946031764071246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writting images:  29%|██▉       | 18580/64320 [11:38<2:07:58,  5.96it/s]"
     ]
    }
   ],
   "source": [
    "# Define the directory path\n",
    "base_dir = './dataset'\n",
    "\n",
    "# Create the 'dataset' folder\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "# Create the 'indata' folder inside 'dataset'\n",
    "indata_dir = os.path.join(base_dir, 'indata')\n",
    "if not os.path.exists(indata_dir):\n",
    "    os.makedirs(indata_dir)\n",
    "\n",
    "# Create the 'outdata' folder inside 'dataset'\n",
    "outdata_dir = os.path.join(base_dir, 'outdata')\n",
    "if not os.path.exists(outdata_dir):\n",
    "    os.makedirs(outdata_dir)\n",
    "\n",
    "path_folder1 = \"./preparations/data/outdata/\"\n",
    "path_folder1_cut = \"./dataset/outdata/\"\n",
    "\n",
    "path_folder2 = \"./preparations/data/indata/\"\n",
    "path_folder2_cut = \"./dataset/indata/\"\n",
    "\n",
    "cut_data(path_folder1, path_folder2, path_folder1_cut, path_folder2_cut, (bordTop, bordLeft))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
