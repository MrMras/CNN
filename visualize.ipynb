{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import config\n",
    "\n",
    "from model_structure import UNet\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PyTorch model\n",
    "model = UNet()\n",
    "model.load_state_dict(torch.load(\"./model_for_vasc.pth\", map_location=\"cpu\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Directory paths for input and output data\n",
    "input_dir = \"./preparations/data/indata\"\n",
    "output_dir = \"./preparations/data/outdata\"\n",
    "\n",
    "# Get a list of image files in the input directory\n",
    "image_files = os.listdir(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4093\n",
      "(512, 512)\n",
      "TP: 0\n",
      "TN: 4068\n",
      "FP: 28\n",
      "FN: 0\n",
      "nan\n",
      "0.9931640625\n",
      "0.9931640625\n",
      "\n",
      "Positive Recall: 0.0\n",
      "Negative Recall: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atashitk\\AppData\\Local\\Temp\\ipykernel_10796\\552638494.py:48: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print(TP / (TP + FN))\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Choose a random pair of input and output files\n",
    "    random_image_file = random.choice(image_files)\n",
    "\n",
    "    # Construct the full file paths\n",
    "    input_image_path = os.path.join(input_dir, random_image_file)\n",
    "    output_label_path = os.path.join(output_dir, random_image_file)\n",
    "    \n",
    "    label_image = cv2.imread(output_label_path, cv2.IMREAD_GRAYSCALE)\n",
    "    shape = label_image.shape\n",
    "    random_x, random_y = random.randint(0, shape[0] - config.WIDTH - 1), random.randint(0, shape[1] - config.HEIGHT - 1)\n",
    "    label_image = label_image[random_y : random_y + config.HEIGHT, random_x : random_x + config.WIDTH]\n",
    "    if cv2.countNonZero(label_image) == 0:\n",
    "        # continue\n",
    "        pass\n",
    "    img = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)[random_y : random_y + config.HEIGHT, random_x : random_x + config.WIDTH]\n",
    "    mask = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2)\n",
    "    input_image = img * (mask // 255)\n",
    "\n",
    "    shape = input_image.shape\n",
    "    break\n",
    "\n",
    "# Perform inference using the model\n",
    "with torch.no_grad():\n",
    "    input_tensor = torch.from_numpy(input_image / 255).unsqueeze(0).float()\n",
    "    output = model(input_tensor)\n",
    "# Convert the output tensor to a NumPy array\n",
    "output_np = output.numpy()\n",
    "# Convert the output prediction to binary format and multiply by 255\n",
    "print((np.unique(output_np).size))\n",
    "binary_output = (output_np >= 0.5).astype(np.uint8)[0] * 255\n",
    "# Display the input image, label, and binary prediction using OpenCV\n",
    "cv2.imshow(\"Input Image\", cv2.resize(input_image, (512, 512)))\n",
    "cv2.imshow(\"Label Image\", cv2.resize(label_image, (512, 512)))\n",
    "print(cv2.resize(binary_output, (512, 512)).shape)\n",
    "cv2.imshow(\"Model Prediction (Binary)\", cv2.resize(binary_output, (512, 512)))\n",
    "cv2.imshow(\"Correctness Image\", cv2.resize((np.multiply(binary_output, label_image) + np.multiply((255 - binary_output), (255 - label_image))) * 255, (512, 512)))\n",
    "\n",
    "TP = np.sum(np.multiply(binary_output, label_image))\n",
    "TN = np.sum(np.multiply((255 - binary_output), (255 - label_image)))\n",
    "FP = np.sum(np.multiply(binary_output, (255 - label_image)))\n",
    "FN = np.sum(np.multiply((255 - binary_output), label_image))\n",
    "print(\"TP:\", TP)\n",
    "print(\"TN:\", TN)\n",
    "print(\"FP:\", FP)\n",
    "print(\"FN:\", FN)\n",
    "\n",
    "print(TP / (TP + FN))\n",
    "print(TN / (TN + FP))\n",
    "print((TP + TN) / (TP + TN + FP + FN))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Positive Recall:\", TP / (TP + FP))\n",
    "print(\"Negative Recall:\", TN / (TN + FN))\n",
    "\n",
    "# Wait for a key press and then close the OpenCV windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img, margin):\n",
    "    if margin != 0:\n",
    "        raise ValueError\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.from_numpy(img / 255).unsqueeze(0).float()\n",
    "        output = model(input_tensor)\n",
    "    output_np = output.numpy()\n",
    "    return output_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random image name: img_1001031.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/80 [00:00<?, ?it/s]C:\\Users\\atashitk\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\functional.py:1352: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
      "  warnings.warn(\"dropout2d: Received a 3D input to dropout2d and assuming that channel-wise \"\n",
      "Processing: 100%|██████████| 80/80 [00:47<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 0.27 %\n",
      "TN: 97.18 %\n",
      "FP: 2.43 %\n",
      "FN: 0.12 %\n",
      "0.6947856675211114\n",
      "0.9756086930689504\n",
      "0.9745098625387654\n",
      "\n",
      "Positive Recall: 0.10063570772280048\n",
      "Negative Recall: 0.9987725705088794\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"./preparations/data/indata\"\n",
    "output_dir = \"./preparations/data/outdata\"\n",
    "\n",
    "margin = 0\n",
    "step = 16\n",
    "# Get a list of image files in the input directory\n",
    "image_files = os.listdir(input_dir)\n",
    "\n",
    "show_size = (512, 512)\n",
    "\n",
    "random_image_file = random.choice(image_files)\n",
    "print(\"Random image name:\", random_image_file)\n",
    "input_image_path = os.path.join(input_dir, random_image_file)\n",
    "output_label_path = os.path.join(output_dir, random_image_file)\n",
    "\n",
    "input_image = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "label_image = cv2.imread(output_label_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "shape = label_image.shape\n",
    "\n",
    "img = input_image[shape[0] % step:, shape[1]%step:]\n",
    "mask = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "input_image = img * (mask // 255)\n",
    "label_image = label_image[shape[0] % step:, shape[1]%step:]\n",
    "\n",
    "shape = label_image.shape\n",
    "count_times = np.zeros(shape)\n",
    "total_times = np.zeros(shape)\n",
    "\n",
    "arr1 = []\n",
    "arr2 = []\n",
    "for i in tqdm(range(0, shape[0] - config.HEIGHT, step), \"Processing\"):\n",
    "    for j in range(0, shape[1] - config.WIDTH, step):\n",
    "        \n",
    "        slice_tmp = input_image[i : i + config.HEIGHT, j : j + config.WIDTH]\n",
    "        # print(i, j, slice.shape)\n",
    "        array_tmp = get_prediction(slice_tmp, margin)[0]\n",
    "        # print(array_tmp.shape)\n",
    "        count_times[i : (i + config.HEIGHT), j : (j + config.WIDTH)] += (array_tmp > 0.5)\n",
    "        \n",
    "        total_times[i : (i + config.HEIGHT), j : (j + config.WIDTH)] += 1\n",
    "\n",
    "        \n",
    "\n",
    "unique = np.unique(count_times)\n",
    "confidence = (count_times + 0.0001) / (total_times + 0.0001)\n",
    "binary_output = (np.floor(confidence * 255))\n",
    "\n",
    "cv2.imshow(\"Input Image\", cv2.resize(input_image, show_size))\n",
    "cv2.imshow(\"Label Image\", cv2.resize(label_image, show_size))\n",
    "cv2.imshow(\"Model Prediction (Binary)\", cv2.resize(binary_output, show_size))\n",
    "cv2.imshow(\"Correctness Image\", cv2.resize((np.multiply(binary_output, label_image) + np.multiply((255 - binary_output), (255 - label_image))) * 255, show_size))\n",
    "\n",
    "TP = np.sum(np.multiply(binary_output, label_image))\n",
    "TN = np.sum(np.multiply((255 - binary_output), (255 - label_image)))\n",
    "FP = np.sum(np.multiply(binary_output, (255 - label_image)))\n",
    "FN = np.sum(np.multiply((255 - binary_output), label_image))\n",
    "print(\"TP:\", np.round(TP / (TP + TN + FP + FN) * 100, 2), \"%\")\n",
    "print(\"TN:\", np.round(TN / (TP + TN + FP + FN) * 100, 2), \"%\")\n",
    "print(\"FP:\", np.round(FP / (TP + TN + FP + FN) * 100, 2), \"%\")\n",
    "print(\"FN:\", np.round(FN / (TP + TN + FP + FN) * 100, 2), \"%\")\n",
    "\n",
    "print(TP / cv2.countNonZero(label_image) / 255 / 255)\n",
    "print(TN / (shape[0] * shape[1] - cv2.countNonZero(label_image)) / 255 / 255)\n",
    "print((TP + TN) / shape[0] / shape[1] / 255 / 255)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Positive Recall:\", TP / (TP + FP))\n",
    "print(\"Negative Recall:\", TN / (TN + FN))\n",
    "\n",
    "# Wait for a key press and then close the OpenCV windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1340/1340 [01:37<00:00, 13.76it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"./preparations/data/indata\"\n",
    "output_dir = \"./dataset/preprocess/\"\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, \"indata\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, \"outdata\"), exist_ok=True)\n",
    "\n",
    "for image_file in tqdm(os.listdir(input_dir)):\n",
    "    input_image_path = os.path.join(input_dir, image_file)\n",
    "    output_image_path1 = os.path.join(output_dir, \"indata\", image_file)\n",
    "    output_image_path2 = os.path.join(output_dir, \"outdata\", image_file)\n",
    "    img = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    output_image = img * (mask // 255)\n",
    "    cv2.imwrite(output_image_path1, output_image)\n",
    "    _, thresh = cv2.threshold(output_image, 41, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imwrite(output_image_path2, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
