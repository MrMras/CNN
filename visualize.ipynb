{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import config\n",
    "\n",
    "from model_structure import UNet\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy as copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PyTorch model\n",
    "model = UNet()\n",
    "model.load_state_dict(torch.load(\"./model_for_vasc.pth\", map_location=\"cpu\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Directory paths for input and output data\n",
    "input_dir = \"./preparations/preprocess/indata\"\n",
    "output_dir = \"./preparations/preprocess/outdata\"\n",
    "\n",
    "# Get a list of image files in the input directory\n",
    "image_files = os.listdir(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     # Choose a random pair of input and output files\n",
    "#     random_image_file = random.choice(image_files)\n",
    "\n",
    "#     # Construct the full file paths\n",
    "#     input_image_path = os.path.join(input_dir, random_image_file)\n",
    "#     output_label_path = os.path.join(output_dir, random_image_file)\n",
    "    \n",
    "#     label_image = cv2.imread(output_label_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     shape = label_image.shape\n",
    "#     random_x, random_y = random.randint(0, shape[0] - config.WIDTH - 1), random.randint(0, shape[1] - config.HEIGHT - 1)\n",
    "#     label_image = label_image[random_y : random_y + config.HEIGHT, random_x : random_x + config.WIDTH]\n",
    "#     if cv2.countNonZero(label_image) == 0:\n",
    "#         continue\n",
    "#         pass\n",
    "#     img = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)[random_y : random_y + config.HEIGHT, random_x : random_x + config.WIDTH]\n",
    "#     mask = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2)\n",
    "#     input_image = img * (mask // 255)\n",
    "\n",
    "#     shape = input_image.shape\n",
    "#     break\n",
    "\n",
    "# # Perform inference using the model\n",
    "# with torch.no_grad():\n",
    "#     input_tensor = torch.from_numpy(input_image / 255).unsqueeze(0).float()\n",
    "#     output = model(input_tensor)\n",
    "# # Convert the output tensor to a NumPy array\n",
    "# output_np = output.numpy()\n",
    "# # Convert the output prediction to binary format and multiply by 255\n",
    "# binary_output = (output_np >= 0.5).astype(np.uint8)[0] * 255\n",
    "# # Display the input image, label, and binary prediction using OpenCV\n",
    "# cv2.imshow(\"Input Image\", cv2.resize(input_image, (512, 512)))\n",
    "# cv2.imshow(\"Label Image\", cv2.resize(label_image, (512, 512)))\n",
    "# cv2.imshow(\"Model Prediction (Binary)\", cv2.resize(binary_output, (512, 512)))\n",
    "# cv2.imshow(\"Correctness Image\", cv2.resize((np.multiply(binary_output, label_image) + np.multiply((255 - binary_output), (255 - label_image))) * 255, (512, 512)))\n",
    "\n",
    "# TP = np.sum(np.multiply(binary_output, label_image))\n",
    "# TN = np.sum(np.multiply((255 - binary_output), (255 - label_image)))\n",
    "# FP = np.sum(np.multiply(binary_output, (255 - label_image)))\n",
    "# FN = np.sum(np.multiply((255 - binary_output), label_image))\n",
    "# print(\"TP:\", TP)\n",
    "# print(\"TN:\", TN)\n",
    "# print(\"FP:\", FP)\n",
    "# print(\"FN:\", FN, \"\\n\")\n",
    "\n",
    "# print(\"Positive accuracy:\", np.round(TP / (TP + FN), 3))\n",
    "# print(\"Negative accuracy:\", np.round(TN / (TN + FP), 3))\n",
    "# print(\"Accuracy:\", np.round((TP + TN) / (TP + TN + FP + FN), 3))\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"Positive Recall:\", np.round(TP / (TP + FP), 3))\n",
    "# print(\"Negative Recall:\", np.round(TN / (TN + FN), 3))\n",
    "\n",
    "# # Wait for a key press and then close the OpenCV windows\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img, margin):\n",
    "    if margin != 0:\n",
    "        raise ValueError\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.from_numpy(img / 255).unsqueeze(0).float()\n",
    "        output = model(input_tensor)\n",
    "    output_np = output.numpy()\n",
    "    return output_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"./preparations/data/indata\"\n",
    "output_dir = \"./preparations/data/outdata\"\n",
    "\n",
    "margin = 0\n",
    "step = 32\n",
    "# Get a list of image files in the input directory\n",
    "image_files = os.listdir(input_dir)\n",
    "\n",
    "show_size = (512, 512)\n",
    "\n",
    "random_image_file = random.choice(image_files)\n",
    "print(\"Random image name:\", random_image_file)\n",
    "# random_image_file = \"img_1000342.png\"\n",
    "input_image_path = os.path.join(input_dir, random_image_file)\n",
    "output_label_path = os.path.join(output_dir, random_image_file)\n",
    "\n",
    "input_image = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "_, label_image = cv2.threshold(input_image, 61, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "shape = label_image.shape\n",
    "\n",
    "input_image = input_image[shape[0] % step:, shape[1]%step:]\n",
    "label_image = label_image[shape[0] % step:, shape[1]%step:]\n",
    "\n",
    "shape = label_image.shape\n",
    "count_times = np.zeros(shape)\n",
    "total_times = np.zeros(shape)\n",
    "\n",
    "arr1 = []\n",
    "arr2 = []\n",
    "for i in tqdm(range(0, shape[0] - shape[0] % step, step), \"Processing\"):\n",
    "    for j in range(0, shape[1] - shape[1] % step, step):\n",
    "        slice_tmp = input_image[i : i + config.HEIGHT, j : j + config.WIDTH]\n",
    "        array_tmp = get_prediction(slice_tmp, margin)[0]\n",
    "        count_times[i : (i + config.HEIGHT), j : (j + config.WIDTH)] += (array_tmp > 0.5)\n",
    "        total_times[i : (i + config.HEIGHT), j : (j + config.WIDTH)] += 1\n",
    "      \n",
    "\n",
    "confidence = (count_times + 0.0001) / (total_times + 0.0001)\n",
    "binary_output = (np.floor(confidence * 255)).astype(np.uint8)\n",
    "\n",
    "# Create a new array with default values (127, 127, 255)\n",
    "result_array = np.full((label_image.shape[0], label_image.shape[1], 3), (0, 0, 0), dtype=np.uint8)\n",
    "\n",
    "# Update values based on conditions\n",
    "result_array[(label_image == 0) & (binary_output == 0), :] = (0, 0, 0)  # Where both are 0\n",
    "result_array[(label_image == 255) & (binary_output == 255), :] = (255, 255, 255)  # Where both are 255\n",
    "result_array[(label_image == 0) & (binary_output == 255), :] = (0, 0, 255)  # Where label_image is 0 and binary_output is 255\n",
    "result_array[(label_image == 255) & (binary_output == 0), :] = (0, 128, 128)  # Where label_image is 255 and binary_output is 0\n",
    "\n",
    "a, b, c = result_array.shape\n",
    "\n",
    "# Calculate the number of rows and columns to keep\n",
    "new_a = a - (a % step)\n",
    "new_b = b - (b % step)\n",
    "\n",
    "# Create copies for later\n",
    "label_image_copy = label_image[:new_a, :new_b]\n",
    "binary_output_copy = binary_output[:new_a, :new_b]\n",
    "# Use array slicing to obtain the desired subarray\n",
    "coef = 0.5\n",
    "\n",
    "input_image = cv2.cvtColor(input_image[:new_a, :new_b], cv2.COLOR_GRAY2RGB)\n",
    "label_image = cv2.cvtColor(label_image[:new_a, :new_b], cv2.COLOR_GRAY2RGB)\n",
    "binary_output = cv2.cvtColor(binary_output[:new_a, :new_b], cv2.COLOR_GRAY2RGB)\n",
    "result_array = result_array[:new_a, :new_b, :]\n",
    "\n",
    "modified_label_image = label_image.copy()\n",
    "COLOR_BG = [1, 1, 1] #BGR WHITE\n",
    "COLOR_BODY = [0, 0, 0] #BGR BLUE\n",
    "\n",
    "modified_label_image[np.all(label_image == [0, 0, 0], axis=-1)] = COLOR_BG\n",
    "modified_label_image[np.all(label_image == [255, 255, 255], axis=-1)] = COLOR_BODY\n",
    "\n",
    "blend_image = input_image * modified_label_image\n",
    "\n",
    "img_vert1 = np.concatenate([cv2.resize(input_image, show_size), cv2.resize(label_image, show_size)], axis=0)\n",
    "img_vert2 = np.concatenate([cv2.resize(blend_image, show_size), cv2.resize(binary_output, show_size)], axis=0).astype(np.uint8)\n",
    "\n",
    "img_collage = np.concatenate([img_vert1, img_vert2], axis=1)\n",
    "\n",
    "# Specify the text, font, and position\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "text_color = (255, 255, 255)  # White color\n",
    "size_x = input_image.shape[0] // 2\n",
    "size_y = input_image.shape[1] // 2\n",
    "text_position_x = 10\n",
    "text_position_y = 25\n",
    "\n",
    "# Use cv2.putText() to overlay text on the image\n",
    "cv2.putText(img_collage, \"Input\", (text_position_x, text_position_y), font, font_scale, text_color, font_thickness)\n",
    "cv2.putText(img_collage, \"Label\", (text_position_x, text_position_y + show_size[1]), font, font_scale, text_color, font_thickness)\n",
    "cv2.putText(img_collage, \"Prediction\", (text_position_x + show_size[0], text_position_y  + show_size[1]), font, font_scale, text_color, font_thickness)\n",
    "cv2.putText(img_collage, \"Blend\", (text_position_x + show_size[0], text_position_y), font, font_scale, text_color, font_thickness)\n",
    "\n",
    "cv2.imshow(\"Input/Output - Label/LabelCorr\", img_collage)\n",
    "cv2.imwrite(\"./gener_image.png\", result_array)\n",
    "\n",
    "TP = np.count_nonzero(np.multiply(binary_output_copy, label_image_copy))\n",
    "TN = np.count_nonzero(np.multiply((255 - binary_output_copy), (255 - label_image_copy)))\n",
    "FP = np.count_nonzero(np.multiply(binary_output_copy, (255 - label_image_copy)))\n",
    "FN = np.count_nonzero(np.multiply((255 - binary_output_copy), label_image_copy))\n",
    "print(\"TP:\", np.round(TP / (TP + TN + FP + FN) * 100, 2), \"%\")\n",
    "print(\"TN:\", np.round(TN / (TP + TN + FP + FN) * 100, 2), \"%\")\n",
    "print(\"FP:\", np.round(FP / (TP + TN + FP + FN) * 100, 2), \"%\")\n",
    "print(\"FN:\", np.round(FN / (TP + TN + FP + FN) * 100, 2), \"%\")\n",
    "\n",
    "print()\n",
    "print(\"Positive accuracy:\", TP / (TP + FN))\n",
    "print(\"Negative accuracy:\", TN / (TN + FP))\n",
    "print(\"Total accuracy:\", (TP + TN) / (TP + TN + FP + FN))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Positive Recall:\", TP / (TP + FP))\n",
    "print(\"Negative Recall:\", TN / (TN + FN))\n",
    "\n",
    "# Wait for a key press and then close the OpenCV windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.putText(result_array, \"Yellow - FP\", (text_position_x, text_position_y), font, font_scale, text_color, font_thickness)\n",
    "cv2.putText(result_array, \"Red - FN\", (text_position_x, 2 * text_position_y), font, font_scale, text_color, font_thickness)\n",
    "cv2.imshow(\"Correctness Image\", result_array)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = \"./preparations/data/indata\"\n",
    "# output_dir = \"./preparations/preprocess/\"\n",
    "# # Create the folder if it doesn't exist\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# os.makedirs(os.path.join(output_dir, \"indata\"), exist_ok=True)\n",
    "# os.makedirs(os.path.join(output_dir, \"outdata\"), exist_ok=True)\n",
    "\n",
    "# for image_file in tqdm(os.listdir(input_dir)):\n",
    "#     input_image_path = os.path.join(input_dir, image_file)\n",
    "#     output_image_path1 = os.path.join(output_dir, \"indata\", image_file)\n",
    "#     output_image_path2 = os.path.join(output_dir, \"outdata\", image_file)\n",
    "#     img = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     mask = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "#     output_image = img * (mask // 255)\n",
    "#     cv2.imwrite(output_image_path1, output_image)\n",
    "#     _, thresh = cv2.threshold(output_image, 61, 255, cv2.THRESH_BINARY)\n",
    "#     cv2.imwrite(output_image_path2, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# import nibabel as nib\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def nii_to_numpy(file_path):\n",
    "#     # Load NRRD file\n",
    "#     nrrd_data = nib.load(file_path)\n",
    "\n",
    "#     # Get the data array from the NRRD file\n",
    "#     nrrd_array = nrrd_data.get_fdata()\n",
    "\n",
    "#     return nrrd_array\n",
    "\n",
    "# # Example usage\n",
    "# nrrd_file_path = \"./single_image.nii\"\n",
    "# numpy_array = np.squeeze(nii_to_numpy(nrrd_file_path), axis=-1)\n",
    "\n",
    "# img_name = \"img_1000342.png\"\n",
    "# img1 = cv2.imread(os.path.join(\"./preparations/data/indata/\", img_name), cv2.IMREAD_GRAYSCALE)\n",
    "# img2 = cv2.imread(os.path.join(\"./preparations/data/outdata\", img_name), cv2.IMREAD_GRAYSCALE)\n",
    "# img3 = np.transpose(numpy_array * 255)\n",
    "\n",
    "# size = (512, 512)\n",
    "# min_err = 2e-10\n",
    "# min_err_threshold = 256\n",
    "\n",
    "# weight = 100\n",
    "\n",
    "\n",
    "# _, img_threshold = cv2.threshold(img1, 61, 255, cv2.THRESH_BINARY)\n",
    "# cv2.imshow(\"Original\", cv2.resize(img1, size))\n",
    "# cv2.imshow(\"Threshold\", cv2.resize(img2, size))\n",
    "# cv2.imshow(\"Manual\", cv2.resize(img3, size))\n",
    "# cv2.imshow(\"Closest\", cv2.resize(img_threshold, size))\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# # Create a new array with default values (255, 0, 0)\n",
    "# result_array = np.full((img3.shape[0], img3.shape[1], 3), (0, 0, 255), dtype=np.uint8)\n",
    "\n",
    "# # Update values based on conditions\n",
    "# result_array[(img3 == 0) & (img_threshold == 0), :] = (0, 0, 0)  # Where both are 0\n",
    "# result_array[(img3 == 255) & (img_threshold == 255), :] = (255, 255, 255)  # Where both are 255\n",
    "\n",
    "\n",
    "# cv2.imshow(\"Errors\", result_array)\n",
    "# cv2.imwrite(\"./image_with_errors.png\", result_array)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
