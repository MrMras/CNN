{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import config\n",
    "import vtk\n",
    "\n",
    "from model_structure_3d import UNet3D\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy as copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PyTorch model\n",
    "model = UNet3D()\n",
    "model.load_state_dict(torch.load(\"./model_for_vasc_3d.pth\", map_location=\"cpu\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Directory paths for input and output data\n",
    "input_dir = \"./preparations/preprocess/indata\"\n",
    "output_dir = \"./preparations/preprocess/outdata\"\n",
    "\n",
    "# Get a list of image files in the input directory\n",
    "image_files = os.listdir(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = random.randint(0, len(image_files) // config.NUM_PICS - 1) * 16\n",
    "\n",
    "# Choose 16 consecutive images starting from the random index\n",
    "label_image = cv2.imread(os.path.join(output_dir, image_files[0]), cv2.IMREAD_GRAYSCALE)\n",
    "shape = label_image.shape\n",
    "\n",
    "while True:\n",
    "    random_x, random_y = random.randint(0, shape[0] - config.WIDTH - 1), random.randint(0, shape[1] - config.HEIGHT - 1)\n",
    "    # Initialize an empty list to store the images\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    for i in range(start_index, start_index + 16):\n",
    "        # Construct the full file paths\n",
    "        input_image_path = os.path.join(input_dir, image_files[i])\n",
    "        output_label_path = os.path.join(output_dir, image_files[i])\n",
    "\n",
    "        label_image = cv2.imread(output_label_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        label_image = label_image[random_y : random_y + config.HEIGHT, random_x : random_x + config.WIDTH]\n",
    "        img = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)[random_y : random_y + config.HEIGHT, random_x : random_x + config.WIDTH]\n",
    "        mask = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        input_image = img * (mask // 255)\n",
    "\n",
    "        # Append the processed image to the list\n",
    "        image_list.append(input_image)\n",
    "        label_list.append(label_image)\n",
    "\n",
    "    # Convert the list of images into a NumPy array\n",
    "    if(np.sum(label_list) > 0):\n",
    "        break\n",
    "\n",
    "image_array = np.array([image_list])\n",
    "label_list = np.array(label_list)\n",
    "\n",
    "print(image_array.shape)\n",
    "\n",
    "# Perform inference using the model\n",
    "with torch.no_grad():\n",
    "    input_tensor = torch.from_numpy(image_array / 255).unsqueeze(0).float()\n",
    "    output = model(input_tensor)\n",
    "# Convert the output tensor to a NumPy array\n",
    "output_np = output.numpy()\n",
    "# Convert the output prediction to binary format and multiply by 255\n",
    "binary_output = (output_np >= 0.5).astype(np.uint8)[0] * 255\n",
    "# Display the input image, label, and binary prediction using OpenCV\n",
    "\n",
    "img_in = ((np.multiply(binary_output, label_image) + np.multiply((255 - binary_output), (255 - label_image))) * 255)[0]\n",
    "print(img_in.shape)\n",
    "new_img = np.array([cv2.resize(x, (512, 512)) for x in img_in])\n",
    "\n",
    "# Define video properties\n",
    "height, width = new_img.shape[1:]\n",
    "channels = 1\n",
    "fps = 3\n",
    "video_duration = len(new_img) / fps\n",
    "\n",
    "# Create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, fps, (width, height))\n",
    "num = 0\n",
    "# Display the frames in OpenCV window\n",
    "for i in range(len(new_img)):\n",
    "    # Convert the frame to uint8 if necessary\n",
    "    new_img[i] = np.uint8(new_img[i])\n",
    "    \n",
    "    # Write the frame to the video file\n",
    "    out.write(new_img[i])\n",
    "\n",
    "    # Display the frame in OpenCV window (uncomment if needed)\n",
    "    img_concat = np.concatenate((new_img[i], cv2.resize(image_array[0][i], (512, 512))), axis=1)\n",
    "    cv2.imshow('Frame' + str(num), img_concat)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    num += 1\n",
    "\n",
    "# Release the VideoWriter and close the OpenCV window if used\n",
    "out.release()\n",
    "\n",
    "print(new_img.shape)\n",
    "# cv2.imshow(\"Input Image\", cv2.resize(image_array, (512, 512)))\n",
    "# cv2.imshow(\"Label Image\", cv2.resize(label_list, (512, 512)))\n",
    "# cv2.imshow(\"Model Prediction (Binary)\", cv2.resize(binary_output, (512, 512)))\n",
    "# cv2.imshow(\"Correctness Image\", cv2.resize((np.multiply(binary_output, label_image) + np.multiply((255 - binary_output), (255 - label_image))) * 255, (512, 512)))\n",
    "\n",
    "TP = np.sum(np.multiply(binary_output, label_image))\n",
    "TN = np.sum(np.multiply((255 - binary_output), (255 - label_image)))\n",
    "FP = np.sum(np.multiply(binary_output, (255 - label_image)))\n",
    "FN = np.sum(np.multiply((255 - binary_output), label_image))\n",
    "print(\"TP:\", TP)\n",
    "print(\"TN:\", TN)\n",
    "print(\"FP:\", FP)\n",
    "print(\"FN:\", FN, \"\\n\")\n",
    "\n",
    "print(\"Positive accuracy:\", np.round(TP / (TP + FN), 3))\n",
    "print(\"Negative accuracy:\", np.round(TN / (TN + FP), 3))\n",
    "print(\"Accuracy:\", np.round((TP + TN) / (TP + TN + FP + FN), 3))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Positive Recall:\", np.round(TP / (TP + FP), 3))\n",
    "print(\"Negative Recall:\", np.round(TN / (TN + FN), 3))\n",
    "print(\"Recall:\", np.round((TP + TN) / (TP + TN + FP + FN), 3))\n",
    "# Wait for a key press and then close the OpenCV windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img, margin):\n",
    "    if margin != 0:\n",
    "        raise ValueError\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.from_numpy(img / 255).unsqueeze(0).float()\n",
    "        output = model(input_tensor)\n",
    "    output_np = output.numpy()\n",
    "    return output_np\n",
    "\n",
    "input_dir = \"./preparations/data/indata\"\n",
    "output_dir = \"./preparations/data/outdata\"\n",
    "\n",
    "margin = 0\n",
    "step = 64\n",
    "# Get a list of image files in the input directory\n",
    "image_files = os.listdir(input_dir)\n",
    "\n",
    "show_size = (512, 512)\n",
    "\n",
    "random_image_file_index = random.randint(0, len(image_files) - config.NUM_PICS)\n",
    "print(\"Random image name:\", image_files[random_image_file_index])\n",
    "# random_image_file = \"img_1000342.png\"\n",
    "input_image_path = [os.path.join(input_dir, image_files[i]) for i in range(random_image_file_index, random_image_file_index + config.NUM_PICS)]\n",
    "output_label_path = [os.path.join(output_dir, image_files[i]) for i in range(random_image_file_index, random_image_file_index + config.NUM_PICS)]\n",
    "\n",
    "input_images = []\n",
    "label_images = []\n",
    "for i in range(config.NUM_PICS):\n",
    "    input_image_tmp = cv2.imread(input_image_path[i], cv2.IMREAD_GRAYSCALE)\n",
    "    _, label_image_tmp = cv2.threshold(input_image_tmp, 61, 255, cv2.THRESH_BINARY)\n",
    "    input_images.append(input_image_tmp)\n",
    "    label_images.append(label_image_tmp)\n",
    "\n",
    "input_images = np.array([input_images])\n",
    "label_images = np.array([label_images])\n",
    "\n",
    "shape = label_images.shape\n",
    "print(shape)\n",
    "\n",
    "input_images = input_images[:, :, shape[0] % step:, shape[1]%step:]\n",
    "label_images = label_images[:, :, shape[0] % step:, shape[1]%step:]\n",
    "\n",
    "shape = label_images.shape\n",
    "\n",
    "count_times = np.zeros(shape)\n",
    "total_times = np.zeros(shape)\n",
    "print(\"Shape between loop:\", input_images.shape)\n",
    "arr1 = []\n",
    "arr2 = []\n",
    "for i in tqdm(range(0, shape[2] - shape[2] % step - config.HEIGHT, step), \"Processing\"):\n",
    "    for j in range(0, shape[3] - shape[3] % step - config.WIDTH, step):\n",
    "        slice_tmp = input_images[:, :, i : i + config.HEIGHT, j : j + config.WIDTH]\n",
    "        array_tmp = get_prediction(slice_tmp, margin)[0]\n",
    "        count_times[:, :, i : (i + config.HEIGHT), j : (j + config.WIDTH)] += (array_tmp > 0.5)\n",
    "        total_times[:, :, i : (i + config.HEIGHT), j : (j + config.WIDTH)] += 1\n",
    "      \n",
    "\n",
    "confidence = (count_times + 0.0001) / (total_times + 0.0001)\n",
    "binary_output = (np.floor(confidence * 255)).astype(np.uint8)\n",
    "\n",
    "label_images = label_images[0]\n",
    "binary_output = binary_output[0]\n",
    "\n",
    "shape = label_images.shape\n",
    "# Create a new array with default values (127, 127, 255)\n",
    "result_array = np.zeros(shape + (3,), dtype=np.uint8)\n",
    "\n",
    "# Update values based on conditions\n",
    "\n",
    "result_array[(label_images == 0) & (binary_output == 0), :] = (0, 0, 0)  # Where both are 0\n",
    "result_array[(label_images == 255) & (binary_output == 255), :] = (255, 255, 255)  # Where both are 255\n",
    "result_array[(label_images == 0) & (binary_output == 255), :] = (0, 0, 255)  # Where label_image is 0 and binary_output is 255\n",
    "result_array[(label_images == 255) & (binary_output == 0), :] = (0, 128, 128)  # Where label_image is 255 and binary_output is 0\n",
    "\n",
    "a, b, c, d = result_array.shape\n",
    "\n",
    "# Calculate the number of rows and columns to keep\n",
    "new_b = b - (b % step)\n",
    "new_c = c - (c % step)\n",
    "\n",
    "# Create copies for later\n",
    "label_image_copy = label_images[:, :new_b, :new_c]\n",
    "binary_output_copy = binary_output[:, :new_b, :new_c]\n",
    "# Use array slicing to obtain the desired subarray\n",
    "coef = 0.5\n",
    "input_images = input_images[0]\n",
    "\n",
    "\n",
    "input_images = np.repeat(input_images[:, :new_b, :new_c, np.newaxis], 3, axis=-1)\n",
    "label_images = np.repeat(label_images[:, :new_b, :new_c, np.newaxis], 3, axis=-1)\n",
    "binary_output = np.repeat(binary_output[:, :new_b, :new_c, np.newaxis], 3, axis=-1)\n",
    "result_array = result_array[:, :new_b, :new_c, :]\n",
    "\n",
    "\n",
    "modified_label_images = label_images.copy()\n",
    "COLOR_BG = [1, 1, 1] #BGR WHITE\n",
    "COLOR_BODY = [0, 0, 0] #BGR BLUE\n",
    "\n",
    "modified_label_images[np.all(label_images == [0, 0, 0], axis=-1)] = COLOR_BG\n",
    "modified_label_images[np.all(label_images == [255, 255, 255], axis=-1)] = COLOR_BODY\n",
    "\n",
    "blend_images = input_images * modified_label_images\n",
    "\n",
    "# Specify the text, font, and position\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "text_color = (255, 255, 255)  # White color\n",
    "size_x = input_images.shape[1] // 2\n",
    "size_y = input_images.shape[2] // 2\n",
    "text_position_x = 10\n",
    "text_position_y = 25\n",
    "\n",
    "for i in range(config.NUM_PICS):\n",
    "\n",
    "    img_vert1 = np.concatenate([cv2.resize(input_images[i], show_size), cv2.resize(label_images[i], show_size)], axis=0)\n",
    "    img_vert2 = np.concatenate([cv2.resize(blend_images[i], show_size), cv2.resize(binary_output[i], show_size)], axis=0).astype(np.uint8)\n",
    "\n",
    "    img_collage = np.concatenate([img_vert1, img_vert2], axis=1)\n",
    "\n",
    "    # Use cv2.putText() to overlay text on the image\n",
    "    cv2.putText(img_collage, \"Input\", (text_position_x, text_position_y), font, font_scale, text_color, font_thickness)\n",
    "    cv2.putText(img_collage, \"Label\", (text_position_x, text_position_y + show_size[1]), font, font_scale, text_color, font_thickness)\n",
    "    cv2.putText(img_collage, \"Prediction\", (text_position_x + show_size[0], text_position_y  + show_size[1]), font, font_scale, text_color, font_thickness)\n",
    "    cv2.putText(img_collage, \"Blend\", (text_position_x + show_size[0], text_position_y), font, font_scale, text_color, font_thickness)\n",
    "\n",
    "    cv2.imshow(\"Input/Output - Label/LabelCorr - Frame \" + str(i), img_collage)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# cv2.imwrite(\"./gener_image.png\", result_array)\n",
    "\n",
    "TP = np.count_nonzero(np.multiply(binary_output_copy, label_image_copy))\n",
    "TN = np.count_nonzero(np.multiply((255 - binary_output_copy), (255 - label_image_copy)))\n",
    "FP = np.count_nonzero(np.multiply(binary_output_copy, (255 - label_image_copy)))\n",
    "FN = np.count_nonzero(np.multiply((255 - binary_output_copy), label_image_copy))\n",
    "print(\"TP:\", np.round(TP / (TP + TN + FP + FN) * 100, 2), \"%\")\n",
    "print(\"TN:\", np.round(TN / (TP + TN + FP + FN) * 100, 2), \"%\")\n",
    "print(\"FP:\", np.round(FP / (TP + TN + FP + FN) * 100, 2), \"%\")\n",
    "print(\"FN:\", np.round(FN / (TP + TN + FP + FN) * 100, 2), \"%\")\n",
    "\n",
    "print()\n",
    "print(\"Positive accuracy:\", TP / (TP + FN))\n",
    "print(\"Negative accuracy:\", TN / (TN + FP))\n",
    "print(\"Total accuracy:\", (TP + TN) / (TP + TN + FP + FN))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Positive Recall:\", TP / (TP + FP))\n",
    "print(\"Negative Recall:\", TN / (TN + FN))\n",
    "\n",
    "# Wait for a key press and then close the OpenCV windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for x in result_array:\n",
    "    img_tmp = x\n",
    "    print(img_tmp.shape)\n",
    "    cv2.putText(img_tmp, \"Yellow - FN\", (text_position_x, text_position_y), font, font_scale, text_color, font_thickness)\n",
    "    cv2.putText(img_tmp, \"Red - FP\", (text_position_x, 2 * text_position_y), font, font_scale, text_color, font_thickness)\n",
    "    cv2.imshow(\"Correctness Image\", img_tmp.astype(np.uint8))\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# cv2.putText(result_array, \"Yellow - FP\", (text_position_x, text_position_y), font, font_scale, text_color, font_thickness)\n",
    "# cv2.putText(result_array, \"Red - FN\", (text_position_x, 2 * text_position_y), font, font_scale, text_color, font_thickness)\n",
    "# cv2.imshow(\"Correctness Image\", result_array)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = \"./preparations/data/indata\"\n",
    "# output_dir = \"./preparations/preprocess/\"\n",
    "# # Create the folder if it doesn't exist\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# os.makedirs(os.path.join(output_dir, \"indata\"), exist_ok=True)\n",
    "# os.makedirs(os.path.join(output_dir, \"outdata\"), exist_ok=True)\n",
    "\n",
    "# for image_file in tqdm(os.listdir(input_dir)):\n",
    "#     input_image_path = os.path.join(input_dir, image_file)\n",
    "#     output_image_path1 = os.path.join(output_dir, \"indata\", image_file)\n",
    "#     output_image_path2 = os.path.join(output_dir, \"outdata\", image_file)\n",
    "#     img = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     mask = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "#     output_image = img * (mask // 255)\n",
    "#     cv2.imwrite(output_image_path1, output_image)\n",
    "#     _, thresh = cv2.threshold(output_image, 61, 255, cv2.THRESH_BINARY)\n",
    "#     cv2.imwrite(output_image_path2, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# import nibabel as nib\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def nii_to_numpy(file_path):\n",
    "#     # Load NRRD file\n",
    "#     nrrd_data = nib.load(file_path)\n",
    "\n",
    "#     # Get the data array from the NRRD file\n",
    "#     nrrd_array = nrrd_data.get_fdata()\n",
    "\n",
    "#     return nrrd_array\n",
    "\n",
    "# # Example usage\n",
    "# nrrd_file_path = \"./single_image.nii\"\n",
    "# numpy_array = np.squeeze(nii_to_numpy(nrrd_file_path), axis=-1)\n",
    "\n",
    "# img_name = \"img_1000342.png\"\n",
    "# img1 = cv2.imread(os.path.join(\"./preparations/data/indata/\", img_name), cv2.IMREAD_GRAYSCALE)\n",
    "# img2 = cv2.imread(os.path.join(\"./preparations/data/outdata\", img_name), cv2.IMREAD_GRAYSCALE)\n",
    "# img3 = np.transpose(numpy_array * 255)\n",
    "\n",
    "# size = (512, 512)\n",
    "# min_err = 2e-10\n",
    "# min_err_threshold = 256\n",
    "\n",
    "# weight = 100\n",
    "\n",
    "\n",
    "# _, img_threshold = cv2.threshold(img1, 61, 255, cv2.THRESH_BINARY)\n",
    "# cv2.imshow(\"Original\", cv2.resize(img1, size))\n",
    "# cv2.imshow(\"Threshold\", cv2.resize(img2, size))\n",
    "# cv2.imshow(\"Manual\", cv2.resize(img3, size))\n",
    "# cv2.imshow(\"Closest\", cv2.resize(img_threshold, size))\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# # Create a new array with default values (255, 0, 0)\n",
    "# result_array = np.full((img3.shape[0], img3.shape[1], 3), (0, 0, 255), dtype=np.uint8)\n",
    "\n",
    "# # Update values based on conditions\n",
    "# result_array[(img3 == 0) & (img_threshold == 0), :] = (0, 0, 0)  # Where both are 0\n",
    "# result_array[(img3 == 255) & (img_threshold == 255), :] = (255, 255, 255)  # Where both are 255\n",
    "\n",
    "\n",
    "# cv2.imshow(\"Errors\", result_array)\n",
    "# cv2.imwrite(\"./image_with_errors.png\", result_array)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_data = os.listdir(\"Z://Artem/orig_data/\")\n",
    "# annotated_data = os.listdir(\"Z://Artem/annotated_data/\")\n",
    "# pic_in = cv2.imread(\"Z://Artem/orig_data/img_1000000.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# pic_out = cv2.imread(\"Z://Artem/annotated_data/img_1000000.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# pic_pred = cv2.imread(\"Z://Artem/CNN_data/img_1000000.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# print(pic_in.shape)\n",
    "# print(pic_out.shape)\n",
    "# print(pic_pred.shape)\n",
    "\n",
    "# orig_data = os.listdir(\"Z://Artem/orig_data/\")\n",
    "# annotated_data = os.listdir(\"Z://Artem/annotated_data/\")\n",
    "\n",
    "# step = 32\n",
    "\n",
    "# # for x in tqdm(orig_data, \"\"):\n",
    "# #     file_path = os.path.join(\"Z://Artem/orig_data/\", x)\n",
    "# #     pic = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "# #     height, width = pic.shape\n",
    "# #     cv2.imwrite(file_path, pic[:height- height % step, :width - width % step])\n",
    "\n",
    "# for x in tqdm(annotated_data, \"\"):\n",
    "#     file_path = os.path.join(\"Z://Artem/annotated_data/\", x)\n",
    "#     pic = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     height, width = pic.shape\n",
    "#     cv2.imwrite(file_path, pic[:height - height % step, :width - width % step])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
